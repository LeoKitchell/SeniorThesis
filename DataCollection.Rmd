---
title: "DataCollection"
author: "Leo Kitchell"
date: "11/3/2021"
output: html_document
---

```{r, include=FALSE}
knitr::opts_chunk$set(
  eval = FALSE)
```

## Purpose
The purpose of this document is to gather data from different sources for my senior thesis. This includes pulling ACS 5 Year data from the census using their API, combining the data from InsideAirbnb, and compiling all other data needed to create my measure of gentrification

```{r}
runtime <- list() #creating a list to track how long each code chunk takes to run on my machine
```

```{r, include=FALSE}
runtime$packagesAndLibraries<-Sys.time()
#Installing relevant packages
#install.packages("censusapi")
#install.packages("quanteda")
#install.packages("stopwords")
#install.packages("httr")
#install.packages("jsonlite")
library(stopwords)
library(quanteda)
library(censusapi)
library(stringr)
library(dplyr)
library(httr)
library(jsonlite)
runtime$packagesAndLibraries<-Sys.time()-runtime$packagesAndLibraries
```

# Airbnb Data
Data has been downloaded from InsideAirbnb for 28 US cities. These data are composed of 3 files for each city. The first file includes every listing within the metropolitan area, a second file contains every review for each listing, and the third contains a forward looking calendar showing the listing's available nights and the price for each night. 

## Stacking Data
Using rbind to stack airbnb data from each filetype (Listings, Calendar, and Reviews) into three dataframes. 
```{r, cache=TRUE}
runtime$stackingData <- Sys.time()
path = "C:/Users/Leo/Desktop/CMC/Senior Year/Fall 2021/SeniorThesis/InsideAirbnbData/Zipped_Data/"
file_list = list.files(path = path,'*.csv')

listing_data <- array()
calendar_data <- array()
review_data <- array()

for (variable in file_list) {
  if(grepl("listings",variable,fixed=TRUE)){
      listing_data <- rbind(listing_data,read.csv(paste(path,variable,sep = "")))
  } else if (grepl("calendar",variable,fixed=TRUE)){
      #calendar_data <- rbind(calendar_data,read.csv(paste(path,variable,sep = "")))#commenting this out because the calendar data takes a long time to R bind and isn't used. 
  } else if (grepl("reviews",variable,fixed=TRUE)){
      review_data <- rbind(review_data,read.csv(paste(path,variable,sep = "")))
  } else{
      print("Error in stacking Airbnb data.")
  }
}
listing_data <- listing_data %>% filter(!is.na(id)) #removes rows with NA listing IDs. 
review_data <- review_data %>% filter(!is.na(id)) #removes rows with NA listing IDs. 

runtime$stackingData <- Sys.time()- runtime$stackingData 
```

## Cleaning Airbnb Review Words

### Remove text formatting
```{r}
runtime$removeTextFormatting <- Sys.time()
#create new column that will become the cleaned review data
review_data$clean_reviews <- review_data$comments

# Remove newlines, carriage returns, tabs, and breaks
review_data$clean_reviews <- str_replace_all(review_data$clean_reviews,'\n', ' ')
review_data$clean_reviews <- str_replace_all(review_data$clean_reviews,'\t', ' ')
review_data$clean_reviews <- str_replace_all(review_data$clean_reviews,'\r', ' ')
review_data$clean_reviews <- str_replace_all(review_data$clean_reviews,'<br/>', ' ')

#Remove punctuation marks
review_data$clean_reviews <- str_replace_all(review_data$clean_reviews, "[[:punct:]]", " ") 
runtime$removeTextFormatting <- Sys.time() - runtime$removeTextFormatting
```

### Remove Stopwords
```{r}
stopwords = stopwords(language = "en", source = "snowball")
##TO DO: remove stopwords 
```

### Stemming
```{r}

```


# Gentrification Data
The specification of gentrification which will be used in this project is heavily inspired by the work of Freeman (2005) and Bates (2013). To compose our gentrification measure we will use Census tract level data on median household income, college attainment, median home value, and percent of the population that is white.

## Census Data

### Setup Census API key to pull data.
```{r}
# Add key to .Renviron
key = "be936e1698dd7dfd657546a6a7088c6306f4e54f"
Sys.setenv(CENSUS_KEY= key)
# Reload .Renviron
readRenviron("~/.Renviron")
# Check to see that the expected key is output in your R console
Sys.getenv("CENSUS_KEY")
```

### Census Variables
Descriptions and codes of variables available in the ACS 5 year dataset located here: https://www.socialexplorer.com/data/ACS2019_5yr/metadata/?ds=ACS19_5yr
```{r}
locationName <- "NAME"
totalPop <- "B01003_001E" #Census table for total population
#rentAsPctInc <- "B25070_001E" #Gross Rent As A Percentage Of Household Income In The Past 12 Months
rentAsPctInc <- "B25071_001E" #	Median Gross Rent As A Percentage Of Household Income In The Past 12 Months (Dollars)
rawRent <-"B25056_001E" #Contract Rent
education <- "B15003_001E" #Educational Attainment For The Population 25 Years And Over [25]


censusVars <- c(locationName,totalPop,education,rawRent,rentAsPctInc)

```

### Selecting States
Getting list of all states to pull census data for, based off of states used in Airbnb data. 
```{r}
setwd("C:/Users/Leo/Desktop/CMC/Senior Year/Fall 2021/SeniorThesis/OtherData/")
fipsCrosswalk <- read.csv("State_Fips_Codes.csv",colClasses = c(State_FIPS = "character"))
includedStates <- c("North Carolina","Texas","Massachusetts","Illinois","Ohio","Colorado","New Jersey","California","Tennessee","Louisiana","New York","Oregon","Washington","Minnesota","District of Columbia", "Virginia", "Maryland")
includedStates <- data.frame(includedStates,TRUE)
includedStates <-right_join(x = fipsCrosswalk,y = includedStates, by = c("State_Name" = "includedStates"))
includedStates <- subset(includedStates,select = c("State_Name","State_FIPS"))
```
### Pulling Data from Census API
Compiling Census Data for all tracts within the States included in the AirBnB data
```{r, cache=TRUE}
nameACS <- "acs/acs5"
vintage <- c(2014,2019)
region <- "tract:*"

censusData <- data.frame()
for (year in vintage) {
  for (fipsCode in includedStates$State_FIPS) {
    state = paste("state:",fipsCode,"+county:*",sep = "")
    print(paste("Now pulling census data for Geography:",state," from vintage:",year))
    stateData <- getCensus(name = nameACS,vintage = year, vars = censusVars, regionin = state, region = region)
    stateData$vintage <- year
    censusData <- rbind(censusData,stateData)
  }
}

#When I run my conversion I'll have a mapping from one airbnb to a block. I'll have two observations, one in 2010 block and one in 2000 block. That #way I know which 2000 and 2010 tracts its in. 
#Condition on all the observations that have no change in the tract from 2000 to 2010.

#Order of Operations
#Code the maplinks from lat and longitude to blocks and tracts
#Pin down gentrification metric
#Pin down explanatory variables
  #Controls: population growth. Avg airbnb rating. Location rating on airbnb. 
  # Run a specification with fixed effects and not
  # A decision tree will rank which variables are most important

#TFIDF? Term frequency inverse document frequency. R should have built in function. It normalizes word frequency. 
#Monday Nov 15th send a rought draft to Gelman. 

```

## Geocoding Airbnb Listings
Mapping latitude to blocks and tracts. Predicted to take ~200 minutes per vintage. 
```{r, cache=TRUE, eval=FALSE}

#listing_data$fullFIPS2000<- "" #creating empty columns to be populated by the loop below
#listing_data$tractFIPS2000 <- ""
#listing_data$fullFIPS2010<- ""
#listing_data$tractFIPS2010 <- ""

#vintage <- c(2000,2010)

start_time <- Sys.time()

#for (year in vintage) {
  for (listing in 1:nrow(listing_data[1:149276,])) {
  lat = listing_data$latitude[listing]
    long = listing_data$longitude[listing]
    url <- paste("https://geo.fcc.gov/api/census/block/find?latitude=",lat,"&longitude=",long,"&censusYear=",2010,"&format=json",sep = "")
    response = GET(url)
    blockData <- response$content%>%rawToChar()%>%fromJSON()
    
    if(is.null(blockData$Block$FIPS)){
        listing_data$fullFIPS2010[listing]<-NA
        listing_data$tractFIPS2010[listing]<-NA
    }else{
        listing_data$fullFIPS2010[listing] <- blockData$Block$FIPS
        listing_data$tractFIPS2010[listing] <- substr(listing_data$fullFIPS2010[listing],1,11)
    }
    if(listing%%1000==0) {
      print(paste(listing,"listings geolocated"))
    }
    #if(listing%%20000==0){
    #  write.csv(listing_data,file = "listing_data_11_4.csv",row.names = FALSE)
    #}
  }
end_time <- Sys.time()
end_time - start_time
#}

write.csv(listing_data,file = "listing_data_11_4.csv",row.names = FALSE)
```

```{r}
listing_data <- subset(read.csv(file = "listing_data_11_4_AM.csv"),select = -c(X))



filter(censusData,censusData$B25071_001E<-100)
censusData %>% filter(B25071_001E<0) %>% count(vintage==2019)
names(censusData)
```

```{r}
apis <- listCensusApis()
View(apis)
path = "C:\Users\Leo\Desktop\LOWE Institute\Airbnb_Migration"
msaCrosswalk <- read.csv()

```


