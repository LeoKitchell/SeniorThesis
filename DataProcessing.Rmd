---
title: "DataProcessing"
author: "Leo Kitchell"
date: "12/03/2021"
output: html_document
---

# Purpose
The code below creates models to predict neighborhood (census tract) level gentrification between 2010-2014 and 2015-2019 using Airbnb data. Prediction is then completed using these models, and the output is mapped.

## Installing Packages & Libraries
```{r,warnings = FALSE}
library(caTools)
library(SnowballC)
library(randomForest)
library(glmnet)
library(tm)
library(tidyverse)
```

# Final Compilation of Listing and Review Data
Data is aggregated at the airbnb listing level. Some final data collection steps are performed here because the data files were too large to push to github

## Stacking Review Data
```{r}
runtime <- list()
runtime$finalCompilation <- Sys.time()
path = "Data/InsideAirbnbData/Zipped_Data/"
file_list = list.files(path,'*.csv')
review_data <- array()
for (variable in file_list) {
  if(grepl("reviews",variable,fixed=TRUE)){
      review_data <- rbind(review_data,read.csv(paste(path,variable,sep = ""),encoding = "UTF-8"))
  } 
}
```

## Eliminating Review Data Outside of Time Window and Aggregating to Listing Level
```{r}
runtime$loadAndFilter <- Sys.time()
### Prefix "t" added representing they will be used for the text analysis portion. Alternately, "t" for tiny.
load("Data/OtherData/Compiled_Thesis_Data.RData")
tReviewData <- review_data %>% filter(!is.na(id)) #removes rows with NA listing IDs. 
tReviewData$date <- as.Date(tReviewData$date)
tReviewData <- tReviewData %>% filter(date >= as.Date("2015-01-01") & date <= as.Date("2019-12-31"))  #only keep reviews between census collection time period: 2015-2019

tReviewData <- tReviewData %>% subset(select = c(listing_id,comments)) #keep only listing_id and text data
tReviewData <- tReviewData %>% group_by(listing_id) %>% mutate(numReviews = n()) #creates a feature for the number of reviews per listing
tReviewData <- aggregate(comments ~ listing_id + numReviews, tReviewData, paste, collapse = " ") #combines all text data for a given listing into one row for that listing
runtime$loadAndFilter <- Sys.time() - runtime$loadAndFilter
```

## Merging Airbnb (Listing Level) and Census Data (Tract Level)
```{r}
tListingData <- listing_data %>% subset(select = c("id","bedrooms","price","minimum_nights","review_scores_rating",
                                                             "review_scores_location","tractFIPS2010"))

colnames(tListingData)[which(names(tListingData) == "price")] <- "listing_price" #renames column titled price to "listing_price". 
                                                                                 #Prevents error of repeated column name in tSparse

airbnbData <- inner_join(tListingData,tReviewData,by = c("id"="listing_id"))

tCensusData <- gentrifiableCensusDataWithDistributionsWide %>% subset(select = c("tractFIPS","NAME.2014","totalPop.2014","popGrowth","gentrificationChange"))
tractData  <- inner_join(tCensusData,airbnbData,by = c("tractFIPS"="tractFIPS2010"))
```

## Airbnb Reviews in Gentrifiable Tracts by Year
To see entire sample, do not run date filtering lines from "Eliminating Review Data Outside..." code section
```{r}
cumulativeReviewFreq = c(0, cumsum(tractData$date)) 
plot(x = tractData$date,cumulativeReviewFreq)
cumulativeReviewPlot <- ggplot(data = tractData,aes(x=as.Date(tractData$date)))

cumulativeReviewPlot <- ggplot(data = tractData, aes(x=as.Date(tractData$date))) + stat_ecdf() +#geom_density(aes(x=as.Date(tractData$date)))
  labs(x="Date of Review", y="Cumulative Percent of Reviews")
cumulativeReviewPlot
save(cumulativeReviewPlot,file = "./Writing/Figures/CumulativePercentofReviews.PNG")
```


## Aggregating Airbnb Data to Tract Level
```{r}
tractReviews <- tractData %>% subset(select = c(tractFIPS,comments))
tractReviews <- aggregate(comments ~ tractFIPS, tractReviews, paste,collapse = " ")

tractDataNoText <-  tractData %>% subset(select = -c(comments))

tractDataNoText <- tractDataNoText %>% group_by(tractFIPS) %>%
                                summarise(gentrificationChange = mean(gentrificationChange,na.rm = TRUE),
                                            totalPop.2014 = mean(totalPop.2014,na.rm = TRUE),
                                            popGrowth = mean(popGrowth,na.rm = TRUE),
                                            review_scores_rating = mean(review_scores_rating,na.rm = TRUE),
                                            review_scores_location = mean(review_scores_location,na.rm = TRUE),
                                            bedrooms = mean(bedrooms,na.rm = TRUE),
                                            listing_price = mean(parse_number(listing_price),na.rm = TRUE),
                                            numListings = n(),
                                            numReviews = sum(numReviews))


tractData <- inner_join(tractDataNoText,tractReviews, by = "tractFIPS")
save(tractDataNoText, file = "Data/OtherData/tractDataNoText.RData")
rm(list = setdiff(ls(), c("tractDataNoText","tractData","listing_data", "runtime"))) #cleaning up environment for storage reasons
runtime$finalCompilation <- Sys.time() - runtime$finalCompilation
```

## Calculating Summary Statistics
```{r}
summary(tractDataNoText[complete.cases(tractDataNoText),])
lapply(tractDataNoText,sd, na.rm=TRUE)
```

# Text Processing
## Creating Location Stopwords
```{r}
includedStates <- listing_data %>% group_by(listing_data$state) %>% summarize() %>% drop_na()
names(includedStates)<-"state_FIPS"
file_list = list.files("./InsideAirbnbData/Zipped_Data/",'*.csv')
cities <- unlist(str_split(file_list,"listings"))
cities <- cities[substr(cities,0,1)=="_"]
cities <- substr(cities,2,nchar(cities)-4)
cities <- tolower(cities)
cities <- c(cities,"angeles","york","diego","francisco","minneapolis")

states <- read.csv("Data/OtherData/State_Fips_Codes.csv",colClasses = "character")
states <- inner_join(states,includedStates,by = c("State_FIPS"="state_FIPS"))
states <- tolower(unlist(states$State_Name))
locationWords <- c("north","east","south","west","northeast","northwest","southeast","southwest",states, cities)
```

## Cleaning Text Data
Removes formatting, stopwords, and stems text. Takes approximately 2 hours to run.
```{r, eval = FALSE}
runtime$corpus <- Sys.time()
corpus <- Corpus(VectorSource(tractData$comments)) 
corpus <- tm_map(corpus, PlainTextDocument)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeWords, "New") #removing for place names (e.g. New York, New Jersey)
corpus <- tm_map(corpus, tolower)
corpus <- tm_map(corpus, removeWords, c("airbnb",stopwords("english"),stopwords("spanish"),locationWords))  #remove stopwords
corpus <- tm_map(corpus, stemDocument)
#save(corpus,file = "Data/OtherData/processedFullCorpus.RData")  #commented out so as to not accidentally overwrite saved data
runtime$corpus <- Sys.time() - runtime$corpus
```

# Model Data Creation
Creating training data for models from the processed corpus. Provides a checkpoint to start from after crashes, etc. 
## Loading Relevant Data and Libraries as Checkpoint
```{r}
library(tm)
library(tidyverse)
lapply(c("Data/OtherData/processedFullCorpus.RData","Data/OtherData/tractDataNoText.RData"),load,envir=.GlobalEnv) #loads necessary data
```

## Creating Matrices of Word Frequencies
Both Bag of Words and TF IDF are created. Different sparsity thresholds are also tested
```{r}
sparsities <- c(.4,.5,.6,.7,.8,.9,.95,.99)
frequencies <- DocumentTermMatrix(corpus)
tfidFrequencies <- DocumentTermMatrix(corpus,control = list(weighting = function(x) weightTfIdf(x, normalize = FALSE)))


sparseList       <- list()
tSparseList      <- list()
sparseListTFIDF   <- list()
tSparseListTFIDF  <- list()

ii<-1
while (ii < length(sparsities)+1) {
  sparseList[[ii]]         <- removeSparseTerms(frequencies, sparsities[ii])
  sparseListTFIDF[[ii]]     <- removeSparseTerms(tfidFrequencies, sparsities[ii])
  tSparseList[[ii]]          <- as.data.frame(as.matrix(sparseList[[ii]]))
  tSparseListTFIDF[[ii]]      <- as.data.frame(as.matrix(sparseListTFIDF[[ii]]))
  colnames(tSparseList[[ii]])     <- make.names(colnames(tSparseList[[ii]]))
  colnames(tSparseListTFIDF[[ii]]) <- make.names(colnames(tSparseListTFIDF[[ii]]))
  ii <- ii+1
}

sparsityLevels <- data.frame(matrix(NA,length(sparsities),2))
sparsityLevels$sparsities <- matrix(sparsities)
sparsityLevels$ncol <- unlist(lapply(tSparseList, ncol))
ggplot(data = sparsityLevels) + geom_col(aes(x=as.character(sparsities), y=ncol))+
  labs(x = "Sparsity Threshold", y = "Number of Unique Stems")
```

## Creating and Combining Predictor Data
Training and Testing data for different sparsity thresholds are created. 
Similar sets are created for a 1% data sample for faster parameter tuning and troubleshoot.
```{r}
trainProportion <- 0.7     #Uses 70% of cases as a training set and 30% as a test case
speedFactor <- .1         #Value between 0 and 1. Percent of tracts to use in training and testing set. When running full model set to 1. 

#Bag of Words Section
indexSparseTrain <- list()
trainSparseList  <- list()
testSparseList   <- list()
indexSpeedSparse <- list()
speedSparseList  <- list()
indexSpeedSparseTrain <- list()
speedTrainSparseList  <- list()
speedTestSparseList   <- list()

#TF IDF Section
indexSparseTrainTFIDF <- list()
trainSparseListTFIDF  <- list()
testSparseListTFIDF   <- list()
indexSpeedSparseTFIDF <- list()
speedSparseListTFIDF  <- list()
indexSpeedSparseTrainTFIDF <- list()
speedTrainSparseListTFIDF  <- list()
speedTestSparseListTFIDF   <- list()

ii<-1
while (ii < length(tSparseList)+1) {
  ##Bag of Words Section
  tSparseList[[ii]]     <- bind_cols(tractDataNoText,tSparseList[[ii]])                 #combine text and structured features
  tSparseList[[ii]]     <- tSparseList[[ii]][,!duplicated(colnames(tSparseList[[ii]]))]           #remove columns with duplicate names
  tSparseList[[ii]]     <- tSparseList[[ii]][complete.cases(tSparseList[[ii]]),]                  #remove rows with NAs and NaNs
  tSparseList[[ii]]     <- subset(tSparseList[[ii]],select = -c(tractFIPS))                       #remove tractFIPS from dataframe  
  seed <- set.seed(2021)
  indexSparseTrain[[ii]]  <- sample(seq_len(nrow(tSparseList[[ii]])), size = nrow(tSparseList[[ii]])*trainProportion) #create a training and testing dataset
  trainSparseList[[ii]] <- tSparseList[[ii]][indexSparseTrain[[ii]],]    
  testSparseList[[ii]]  <- tSparseList[[ii]][-indexSparseTrain[[ii]],]
  
  indexSpeedSparse[[ii]]  <- sample(seq_len(nrow(tSparseList[[ii]])), size = nrow(tSparseList[[ii]])*speedFactor)   #create a subset of the full dataset to train small models on
  speedSparseList[[ii]] <- tSparseList[[ii]][indexSpeedSparse[[ii]],]
  
  indexSpeedSparseTrain[[ii]]  <- sample(seq_len(nrow(speedSparseList[[ii]])), size = nrow(speedSparseList[[ii]])*trainProportion)
  speedTrainSparseList[[ii]] <-speedSparseList[[ii]][indexSpeedSparseTrain[[ii]],] 
  speedTestSparseList[[ii]] <- speedSparseList[[ii]][-indexSpeedSparseTrain[[ii]],] 
  
  ##TF IDF Section
  tSparseListTFIDF[[ii]]     <- bind_cols(tractDataNoText,tSparseListTFIDF[[ii]])                 #combine text and structured features
  tSparseListTFIDF[[ii]]     <- tSparseListTFIDF[[ii]][,!duplicated(colnames(tSparseListTFIDF[[ii]]))]           #remove columns with duplicate names
  tSparseListTFIDF[[ii]]     <- tSparseListTFIDF[[ii]][complete.cases(tSparseListTFIDF[[ii]]),]                  #remove rows with NAs and NaNs
  tSparseListTFIDF[[ii]]     <- subset(tSparseListTFIDF[[ii]],select = -c(tractFIPS))                       #remove tractFIPS from dataframe  
  
  indexSparseTrainTFIDF[[ii]]  <- sample(seq_len(nrow(tSparseListTFIDF[[ii]])), size = nrow(tSparseListTFIDF[[ii]])*trainProportion) #create a training and testing dataset
  trainSparseListTFIDF[[ii]] <- tSparseListTFIDF[[ii]][indexSparseTrainTFIDF[[ii]],]    
  testSparseListTFIDF[[ii]]  <- tSparseListTFIDF[[ii]][-indexSparseTrainTFIDF[[ii]],]
  
  indexSpeedSparseTFIDF[[ii]]  <- sample(seq_len(nrow(tSparseListTFIDF[[ii]])), size = nrow(tSparseListTFIDF[[ii]])*speedFactor)   #create a subset of the full dataset to train small models on
  speedSparseListTFIDF[[ii]] <- tSparseListTFIDF[[ii]][indexSpeedSparseTFIDF[[ii]],]
  
  indexSpeedSparseTrainTFIDF[[ii]]  <- sample(seq_len(nrow(speedSparseListTFIDF[[ii]])), size = nrow(speedSparseListTFIDF[[ii]])*trainProportion)
  speedTrainSparseListTFIDF[[ii]] <-speedSparseListTFIDF[[ii]][indexSpeedSparseTrainTFIDF[[ii]],] 
  speedTestSparseListTFIDF[[ii]] <- speedSparseListTFIDF[[ii]][-indexSpeedSparseTrainTFIDF[[ii]],]  
  ii<-ii+1 
}

testData <- list(testSparseList[[1]]$gentrificationChange,testSparseListTFIDF[[1]]$gentrificationChange,
              speedTestSparseList[[1]]$gentrificationChange,speedTestSparseListTFIDF[[1]]$gentrificationChange)
#save(testData,file = "Data/OtherData/testData.RData")
```
# Random Forest Models - Training and Testing
Trains a variety of random forest models using different parameters and data sets. Small data models can be unstable in multithreaded operations. 
## Large RFs
### Random Forests - Full Data, Large Model, Bag of Words
Uses Full data set and 200 trees
```{r, warning=FALSE}
library(caret)
library(ranger)
runtime$largeRangers <- Sys.time()
rangerLargeModels <- list()
predictLargeRangers <- list()
impPlotsLargeRanger <- list(list())

ii<-1
while (ii <= length(tSparseList)) {
      rangerLargeModels[[ii]] <- caret::train(
                                      x = tSparseList[[ii]][,-1],
                                      y = tSparseList[[ii]][,1][[1]],
                                      method = "ranger",
                                      importance = "impurity",
                                      num.trees = 200)
#      predictLargeRangers[[ii]] <- predict(rangerLargeModels[[ii]],newdata = testSparseList[[ii]])
      impPlotsLargeRanger[[ii]] <- plot(varImp(rangerLargeModels[[ii]]),top = 15)
      save(list = c("rangerLargeModels","impPlotsLargeRanger","predictLargeRangers"),file = "Data/OtherData/largeRangerResults.RData")
      print(paste("Model",ii,"finished and saved at",Sys.time()))
      ii<-ii+1
}

# testMSELargeRanger <- double()
# ii<-1
# while (ii <= length(rangerLargeModels)) {
#   testMSELargeRanger[ii] <- sum((predictLargeRangers[[ii]]-testData[[1]])**2)/length(testData[[1]])
#   ii <- ii+1
# }

runtime$largeRangers <- Sys.time() - runtime$largeRangers

```

### Random Forests - Full Data, Large Model, TF IDF
Uses the Full data set and 200 trees
```{r,warning=FALSE}
library(caret)
library(ranger)
runtime$largeRangersTFIDF <- Sys.time()
rangerLargeModelsTFIDF <- list()
predictLargeRangersTFIDF <- list()
impPlotsLargeRangerTFIDF <- list()

ii<-1
while (ii <= length(tSparseListTFIDF)) {
      rangerLargeModelsTFIDF[[ii]] <- caret::train(
                                      x = tSparseListTFIDF[[ii]][,-1],
                                      y = tSparseListTFIDF[[ii]][,1][[1]],
                                      method = "ranger",
                                      importance = "impurity",
                                      num.trees = 200)
#      predictLargeRangersTFIDF[[ii]] <- predict(rangerLargeModelsTFIDF[[ii]],newdata = testSparseListTFIDF[[ii]])
      impPlotsLargeRangerTFIDF[[ii]] <- plot(varImp(rangerLargeModelsTFIDF[[ii]]),top = 15)
      save(list = c("rangerLargeModelsTFIDF","impPlotsLargeRangerTFIDF","predictLargeRangersTFIDF"),file = "Data/OtherData/largeRangerResultsTFIDF.RData")
      print(paste("Model",ii,"finished and saved at",Sys.time()))
      ii<-ii+1
}

# 
# testMSELargeRangerTFIDF <- double()
# ii<-1
# while (ii <= length(rangerLargeModelsTFIDF)) {
#   testMSELargeRangerTFIDF[ii] <- sum((predictLargeRangersTFIDF[[ii]]-testData[[2]])**2)/length(testData[[2]])
#   ii <- ii+1
# }
runtime$largeRangersTFIDF <- Sys.time() - runtime$largeRangersTFIDF

impPlotsLargeRangerTFIDF

```

### Random Forest - Only Structured Features,  Full Data, Large Model
```{r,warning=FALSE}
runtime$largeRangersStructured <- Sys.time()
rangerLargeModelsStructured <- list()
predictLargeRangersStructured <- list()
impPlotsLargeRangerStructured <- list()
tSparseListStructured <- lapply(trainSparseList, "[", c(1:9))
#trainSparseListStructured <- lapply(trainSparseList, "[", c(1:9))
#testSparseListStructured  <- lapply(testSparseList,"[", c(1:9))


ii<-1
while (ii <= length(trainSparseList)) {
      rangerLargeModelsStructured[[ii]] <- caret::train(
                                      x = tSparseListStructured[[ii]][,-1],
                                      y = tSparseListStructured[[ii]][,1][[1]],
                                      method = "ranger",
                                      importance = "impurity",
                                      num.trees = 200)
#      predictLargeRangersStructured[[ii]] <- predict(rangerLargeModelsStructured[[ii]],newdata = testSparseList[[ii]])
      impPlotsLargeRangerStructured[[ii]] <- plot(varImp(rangerLargeModelsStructured[[ii]]),top = 15)
      save(list = c("rangerLargeModelsStructured","impPlotsLargeRangerStructured","predictLargeRangersStructured"),
           file = "Data/OtherData/largeRangerResultsStructured.RData")
      print(paste("Model",ii,"finished and saved at",Sys.time()))
      ii<-ii+1
}


# testMSELargeRangerStructured <- double()
# ii<-1
# while (ii <= length(rangerLargeModelsStructured)) {
#   testMSELargeRangerStructured[ii] <- sum((predictLargeRangersStructured[[ii]]-testData[[1]])**2)/length(testData[[1]])
#   ii <- ii+1
# }
# testMSELargeRangerStructured
ii<-1
while (ii <= length(trainSparseList)) {
  print(paste("Model with sparsity =",ii," has r squared:",rangerLargeModelsStructured[[ii]]$finalModel$r.squared))
  print(paste("Model with sparsity =",ii," has MSE:",rangerLargeModelsStructured[[ii]]$finalModel$prediction.error))
  ii <- ii+1
}
runtime$largeRangersStructured <- Sys.time() - runtime$largeRangersStructured
```

### Random Forest - Only Structured Features, Full Data, Large Model, TFIDF
```{r}
runtime$largeRangersStructuredTFIDF <- Sys.time()
rangerLargeModelsStructuredTFIDF <- list()
predictLargeRangersStructuredTFIDF <- list()
impPlotsLargeRangerStructuredTFIDF <- list()
tSparseListStructuredTFIDF <- lapply(trainSparseListTFIDF, "[", c(1:9))
trainSparseListStructuredTFIDF <- lapply(trainSparseListTFIDF, "[", c(1:9))
testSparseListStructuredTFIDF  <- lapply(testSparseListTFIDF,"[", c(1:9))


ii<-1
while (ii <= length(trainSparseListTFIDF)) {
      rangerLargeModelsStructuredTFIDF[[ii]] <- caret::train(
                                      x = tSparseListStructuredTFIDF[[ii]][,-1],
                                      y = tSparseListStructuredTFIDF[[ii]][,1][[1]],
                                      method = "ranger",
                                      importance = "impurity",
                                      num.trees = 200)
 #     predictLargeRangersStructuredTFIDF[[ii]] <- predict(rangerLargeModelsStructuredTFIDF[[ii]],newdata = testSparseListTFIDF[[ii]])
      impPlotsLargeRangerStructuredTFIDF[[ii]] <- plot(varImp(rangerLargeModelsStructuredTFIDF[[ii]]),top = 15)
      save(list = c("rangerLargeModelsStructuredTFIDF","impPlotsLargeRangerStructuredTFIDF","predictLargeRangersStructuredTFIDF"),
           file = "Data/OtherData/largeRangerResultsStructuredTFIDF.RData")
      print(paste("Model",ii,"finished and saved at",Sys.time()))
      ii<-ii+1
}

# testMSELargeRangerStructuredTFIDF <- double()
# ii<-1
# while (ii <= length(rangerLargeModelsStructuredTFIDF)) {
#   testMSELargeRangerStructuredTFIDF[ii] <- sum((predictLargeRangersStructuredTFIDF[[ii]]-testData[[2]])**2)/length(testData[[2]])
#   ii <- ii+1
# }
# testMSELargeRangerStructuredTFIDF
runtime$largeRangersStructuredTFIDF <- Sys.time() - runtime$largeRangersStructuredTFIDF
```

### Random Forests - Full Data, Extra Large Model, Bag of Words
Uses Full data set and 500 trees
```{r, warning=FALSE}
runtime$extraLargeRangers <- Sys.time()
rangerExtraLargeModels <- list()
predictExtraLargeRangers <- list()
impPlotsExtraLargeRanger <- list(list())

ii<-1
while (ii <= length(trainSparseList)) {
      rangerExtraLargeModels[[ii]] <- caret::train(
                                      x = tSparseList[[ii]][[ii]][,-1],
                                      y = tSparseList[[ii]][[ii]][,1][[1]],
                                      method = "ranger",
                                      importance = "impurity",
                                      num.trees = 500)
#      predictExtraLargeRangers[[ii]] <- predict(rangerExtraLargeModels[[ii]],newdata = testSparseList[[ii]])
      impPlotsExtraLargeRanger[[ii]] <- plot(varImp(rangerExtraLargeModels[[ii]]),top = 15)
      save(list = c("rangerExtraLargeModels","impPlotsExtraLargeRanger","predictExtraLargeRangers"),file = "Data/OtherData/extraLargeRangerResults.RData")
      print(paste("Model",ii,"finished and saved at",Sys.time()))
      ii<-ii+1
}

# testMSEExtraLargeRanger <- double()
# ii<-1
# while (ii <= length(rangerExtraLargeModels)) {
#   testMSEExtraLargeRanger[ii] <- sum((predictLargeRangers[[ii]]-testData[[1]])**2)/length(testData[[1]])
#   ii <- ii+1
# }

runtime$extraLargeRangers <- Sys.time() - runtime$extraLargeRangers
```

### Random Forests - Full Data, Extra Large Model, TF IDF
Uses the Full data set and 500 trees
```{r}
runtime$extraLargeRangersTFIDF <- Sys.time()
rangerExtraLargeModelsTFIDF <- list()
predictExtraLargeRangersTFIDF <- list()
impPlotsExtraLargeRangerTFIDF <- list()

ii<-1
while (ii <= length(trainSparseListTFIDF)) {
      rangerExtraLargeModelsTFIDF[[ii]] <- caret::train(gentrificationChange ~ .,
                                      data = tSparseListTFIDF[[ii]],
                                      method = "ranger",
                                      importance = "impurity",
                                      num.trees = 500)
#      predictExtraLargeRangersTFIDF[[ii]] <- predict(rangerExtraLargeModelsTFIDF[[ii]],newdata = testSparseListTFIDF[[ii]])
      impPlotsExtraLargeRangerTFIDF[[ii]] <- plot(varImp(rangerExtraLargeModelsTFIDF[[ii]]),top = 15)
      save(list = c("rangerExtraLargeModelsTFIDF","impPlotsExtraLargeRangerTFIDF","predictExtraLargeRangersTFIDF","runtime"),
           file = "Data/OtherData/extraLargeRangerResultsTFIDF.RData")
      print(paste("Model",ii,"finished and saved at",Sys.time()))
      ii<-ii+1
}
# ii<-1
# while (ii <= length(rangerExtraLargeModels)) {
#   testMSEExtraLargeRanger[ii] <- sum((predictLargeRangers[[ii]]-testData[[2]])**2)/length(testData[[2]])
#   ii <- ii+1
# }
runtime$extraLargeRangersTFIDF <- Sys.time() - runtime$extraLargeRangersTFIDF
```


## Small RFs
### Random Forests - Small Data, Small Model, Bag of Words, Only Structured
Uses 1% data set and 15 trees
```{r, warning=FALSE}
runtime$smallRangersStructured <- Sys.time()
rangerSmallModelsStructured <- list()
predictSmallRangersStructured <- list()
impPlotsSmallRangerStructured <- list()
speedSparseListStructured <- lapply(speedSparseList, "[", c(1:9))
#speedTestSparseListStructured  <- lapply(speedTestSparseList,"[", c(1:9))


ii<-1
while (ii <= length(speedTrainSparseList)) {
      rangerSmallModelsStructured[[ii]] <- caret::train(
                                      x = speedSparseListStructured[[ii]][,-1],
                                      y = speedSparseListStructured[[ii]][,1][[1]],
                                      method = "ranger",
                                      importance = "impurity",
                                      num.trees = 15)
#      predictSmallRangersStructured[[ii]] <- predict(rangerSmallModels[[ii]],newdata = speedTestSparseListStructured[[ii]])
      impPlotsSmallRangerStructured[[ii]] <- plot(varImp(rangerSmallModelsStructured[[ii]]),top = 15)
      save(list = c("rangerSmallModelsStructured","impPlotsSmallRangerStructured","predictSmallRangersStructured"),
           file = "Data/OtherData/smallRangerResultsStructured.RData")
      print(paste("Model",ii,"finished and saved at",Sys.time()))
      ii<-ii+1
}

ii<-1
while (ii <= length(rangerSmallModelsStructured)) {
   print(rangerSmallModelsStructured[[ii]]$finalModel$prediction.error)
   ii <- ii+1
}
runtime$smallRangersStructured <- Sys.time() - runtime$smallRangersStructured
```

### Random Forests - Small Data, Small Model, TF IDF
Uses 1% data set and 15 trees
```{r}
runtime$smallRangersTFIDF <- Sys.time()
rangerSmallModelsTFIDF <- list()
predictSmallRangersTFIDF <- list()
impPlotsSmallRangerTFIDF <- list()

ii<-1
while (ii <= length(speedTrainSparseListTFIDF)) {
      rangerSmallModelsTFIDF[[ii]] <- caret::train(gentrificationChange ~ .,
                                      data = speedSparseListTFIDF[[ii]],
                                      method = "ranger",
                                      importance = "impurity",
                                      num.trees = 15)
      predictSmallRangersTFIDF[[ii]] <- predict(rangerSmallModelsTFIDF[[ii]],newdata = speedTestSparseListTFIDF[[ii]])
      impPlotsSmallRangerTFIDF[[ii]] <- plot(varImp(rangerSmallModelsTFIDF[[ii]]),top = 15)
      print(paste("Model",ii,"finished at",Sys.time()))
      ii<-ii+1
}


save(list = c("rangerSmallModelsTFIDF","impPlotsSmallRangerTFIDF","predictSmallRangersTFIDF"),file = "Data/OtherData/smallRangerResultsTFIDF.RData")

ii<-1
while (ii < 7) {
  print(paste("Model TFIDF with sparsity =",ii," has r squared:",rangerSmallModelsTFIDF[[ii]]$finalModel$r.squared))
  print(paste("Model TFIDF with sparsity =",ii," has MSE:",rangerSmallModelsTFIDF[[ii]]$finalModel$prediction.error))
  ii <- ii+1
}
runtime$smallRangersTFIDF <- Sys.time() - runtime$smallRangersTFIDF
impPlotsLargeRangerStructured
ii<-1
while (ii < 9) {
  #print(paste("Model TFIDF with sparsity =",ii," has r squared:",rangerLargeModelsStructured[[ii]]$finalModel$r.squared))
  print(paste("Model TFIDF with sparsity =",ii," has MSE:",rangerLargeModelsTFIDF[[ii]]$finalModel$prediction.error))
  ii <- ii+1
}
```


# Other Model Training and Testing
Regularized linear regression models are evaluated. Performance was consistently inferior to Random Forest models, so code may not be maintained. 
## Ridge Regression
```{r}
x <- as.matrix(subset(trainSparse, select = -gentrificationChange))
y <- subset(trainSparse, select = gentrificationChange)
ridgeReg <- cv.glmnet(x = x[],
                      y = y[,],
                      alpha = 0)
bestLambdaRidge <- ridgeReg$lambda.min
bestFitRidge <- ridgeReg$glmnet.fit
bestRidgeReg <- glmnet(x[], y[,], alpha = 0, lambda = bestLambdaRidge)

testSparse$predictedGentrification <- predict(bestRidgeReg,
                                              s = bestLambdaRidge,
                                              newx =as.matrix(subset(testSparse,
                                                                      select = -c(gentrificationChange)))[])
rssRidge <- sum((testSparse$predictedGentrification - testSparse$gentrificationChange)^2)
tssRidge <- sum((testSparse$gentrificationChange - mean(testSparse$gentrificationChange))^2)
rsqRidge <- 1 - rssRidge/tssRidge
rsqRidge
plot(ridgeReg)
```

## lasso Regression
```{r}
runtime$lasso <- Sys.time()
x <- as.matrix(subset(trainSparse, select = -gentrificationChange))
y <- subset(trainSparse, select = gentrificationChange)
lassoReg <- cv.glmnet(x = x[],
                      y = y[,],
                      alpha = 1)
bestLambdaLasso <- lassoReg$lambda.min
bestFitLasso <- lassoReg$glmnet.fit
bestLassoReg <- glmnet(x[], y[,], alpha = 1, lambda = bestLambdaLasso)

testSparse$predictedGentrification <- predict(bestlassoReg,
                                              s = bestLambdalasso,
                                              newx = as.matrix(subset(testSparse, 
                                                                      select = -c(gentrificationChange,predictedGentrification)))[])
rsslasso <- sum((testSparse$predictedGentrification - testSparse$gentrificationChange)^2)
tsslasso <- sum((testSparse$gentrificationChange - mean(testSparse$gentrificationChange))^2)
rsqlasso <- 1 - rsslasso/tsslasso
rsqlasso
plot(lassoReg)
runtime$lasso <- Sys.time() - runtime$lasso
print(Sys.time())
```




# Final Model Selection
## Data Processing
### Loading Trained Model Data and Libraries as Checkpoint
```{r}
library(ranger)
library(tidyverse)
results <- c(list.files("Data/OtherData/","*RangerResults.RData"),list.files("Data/OtherData/","*RangerResultsTFIDF.RData"))
lapply(X = paste("Data/OtherData/",results,sep=""),FUN = load,envir=.GlobalEnv,) #loads models
```

### Creating Data Frame of Large Model Results
```{r}
eightLevelSparsity <- c(.4,.5,.6,.7,.8,.9,.95,.99)

ii<-1
rangerResults <- data.frame(matrix(ncol = 8,nrow = 1))
colnames(rangerResults) <- c("modelType","trainDataSize","sparsity","rsquared","MSE","NumTrees","mTry","minNodeSize")
rangerResults[1,] <- 1
while (ii <= length(rangerExtraLargeModels)) {
  row1  <- c("Bag of Words",rangerLargeModels[[ii]]$finalModel$num.samples,eightLevelSparsity[ii],
           rangerLargeModels[[ii]]$finalModel$r.squared,
           rangerLargeModels[[ii]]$finalModel$prediction.error,
           rangerLargeModels[[ii]]$finalModel$num.trees,
           rangerLargeModels[[ii]]$finalModel$mtry,
           rangerLargeModels[[ii]]$finalModel$min.node.size)
  row2 <- c("TF IDF",rangerLargeModels[[ii]]$finalModel$num.samples,eightLevelSparsity[ii],
           rangerLargeModelsTFIDF[[ii]]$finalModel$r.squared,
           rangerLargeModelsTFIDF[[ii]]$finalModel$prediction.error,
           rangerLargeModelsTFIDF[[ii]]$finalModel$num.trees,
           rangerLargeModelsTFIDF[[ii]]$finalModel$mtry,
           rangerLargeModelsTFIDF[[ii]]$finalModel$min.node.size)
  row3 <- c("Bag of Words",rangerExtraLargeModelsTFIDF[[ii]]$finalModel$num.samples,eightLevelSparsity[ii],
           rangerExtraLargeModels[[ii]]$finalModel$r.squared,
           rangerExtraLargeModels[[ii]]$finalModel$prediction.error,
           rangerExtraLargeModels[[ii]]$finalModel$num.trees,
           rangerExtraLargeModels[[ii]]$finalModel$mtry,
           rangerExtraLargeModels[[ii]]$finalModel$min.node.size)  
  row4 <- c("TF IDF",rangerExtraLargeModelsTFIDF[[ii]]$finalModel$num.samples,eightLevelSparsity[ii],
           rangerExtraLargeModelsTFIDF[[ii]]$finalModel$r.squared,
           rangerExtraLargeModelsTFIDF[[ii]]$finalModel$prediction.error,
           rangerExtraLargeModelsTFIDF[[ii]]$finalModel$num.trees,
           rangerExtraLargeModelsTFIDF[[ii]]$finalModel$mtry,
           rangerExtraLargeModelsTFIDF[[ii]]$finalModel$min.node.size)
  rangerResults <- rbind(rangerResults,row1,row2,row3,row4)
  ii <- ii+1
}
rangerResults <- rangerResults[2:nrow(rangerResults),]
rangerResults$modelName <- paste(rangerResults$modelType,rangerResults$NumTrees,sep="; nTrees: ")
```

## Plotting Model Results
```{r}
library(ggplot2)

modelAccuracybySparsity <- ggplot(data = rangerResults, aes(x = sparsity, y = as.double(MSE), group = modelName)) +
      geom_line(aes(color = modelName)) + labs(title = "Model Accuracy by Sparsity and NTrees", x = "Text Sparsity",subtitle = "Optimal mTry  Selected From 2, sqrt(n), n",color = "Model Type") + ylab("Mean Squared Error") + theme(legend.position = "bottom", legend.box = "vertical") + guides(color=guide_legend(nrow=2, byrow=TRUE))
modelAccuracybySparsity
ggsave(filename = "./Writing/Figures/ModelAccuracyBySparsity.PNG")

ggplot(data = rangerResults, aes(x = sparsity, y = as.double(rsquared), group = modelName)) +
      geom_line(aes(color = modelName)) + labs(title = "RSquared by Sparsity and NTrees", x = "Text Sparsity", subtitle = "Optimal mTry  Selected From 2, sqrt(n), n",color = "Model Type" ) + ylab("R Squared") + theme(legend.position = "bottom",legend.box="vertical")

```
## Tuning Mtry
```{r}
#Runtimes (Intel i9-9900 @ 3.1GHz, 64GB RAM @ 2666MHz):
  #BOW,   200 Trees, 8 Sparsities:  8.803  Hours
  #TFIDF, 200 Trees, 8 Sparsities:  8.824  Hours
  #BOW,   500 Trees, 8 Sparsities:  22.124 Hours
  #TF IDF,500 Trees, 8 Sparsities:  22.193 Hours

#MSE of Sparsity = 0.99 (~14000 columns) Results not significantly better than Sparsity = 0.9 (~3000 columns).
#Sparsity of 0.9 used in final model specification.
sparseOptimal <- 6 #optimal mtry is 913 and 2690
sparseOptimal <- 5 #optimal mtry is 488

#Mtry manually tuned with differing levels of mtryStart, stepFactor, and improve. Final tuning run shown below.
tunedExtraLargeRanger <- tuneMtryFast( gentrificationChange ~ .,
                                       data = tSparseList[[sparseOptimal]],
                                       method = "ranger",
                                       importance = "impurity",
                                       num.trees = 50,
                                       plot = TRUE,
                                       mtryStart = 800,#488,#913, #2690 provides a similar prediction error
                                       stepFactor = 1.1,
                                       improve = 0.00001,
                                       trace = TRUE)
```

## Candidate Models - Training
### Training Candidate Final Models - Mtry of 913
```{r}
runtime <- list()
mtryOptimal <- 913
sparseOptimal <- 6
ntreeOptimal <- 500

tGrid <- expand.grid(
                     .mtry = mtryOptimal,
                     .splitrule = "variance",
                     .min.node.size = 5)
runtime$optimalRanger1 <- Sys.time()
optimalRanger <- caret::train(x = tSparseList[[sparseOptimal]][,-1],
                              y = tSparseList[[sparseOptimal]][,1][[1]],
                              method = "ranger",
                              importance = "impurity",
                              num.trees = ntreeOptimal,
                              tuneGrid = tGrid)
impPlotsOptimalRanger <- plot(varImp(optimalRanger),top = 15)
save(list = c("optimalRanger","impPlotsOptimalRanger"),file = "Data/OtherData/optimalRangerResults.RData")
print(paste("Model finished and saved at",Sys.time()))
runtime$optimalRanger1 <- Sys.time() - runtime$optimalRanger1


runtime$optimalRanger2 <- Sys.time()
sparseOptimal <- 7
optimalRanger2 <- caret::train(x = tSparseList[[sparseOptimal]][,-1],
                              y = tSparseList[[sparseOptimal]][,1][[1]],
                              method = "ranger",
                              importance = "impurity",
                              num.trees = ntreeOptimal,
                              tuneGrid = tGrid)
impPlotsOptimalRanger2 <- plot(varImp(optimalRanger2),top = 15)
save(list = c("optimalRanger2","impPlotsOptimalRanger2"),file = "Data/OtherData/optimalRangerResults2.RData")
print(paste("Model finished and saved at",Sys.time()))
runtime$optimalRanger2 <- Sys.time() - runtime$optimalRanger2


runtime$optimalRanger3 <- Sys.time()
sparseOptimal <- 8
optimalRanger3 <- caret::train(x = tSparseList[[sparseOptimal]][,-1],
                              y = tSparseList[[sparseOptimal]][,1][[1]],
                              method = "ranger",
                              importance = "impurity",
                              num.trees = ntreeOptimal,
                              tuneGrid = tGrid)
impPlotsOptimalRanger3 <- plot(varImp(optimalRanger3),top = 15)
save(list = c("optimalRanger3","impPlotsOptimalRanger3"),file = "Data/OtherData/optimalRangerResults3.RData")
print(paste("Model finished and saved at",Sys.time()))
runtime$optimalRanger3 <- Sys.time() - runtime$optimalRanger3

runtime$optimalRanger4 <- Sys.time()
sparseOptimal <- 5
optimalRanger4 <- caret::train(x = tSparseList[[sparseOptimal]][,-1],
                              y = tSparseList[[sparseOptimal]][,1][[1]],
                              method = "ranger",
                              importance = "impurity",
                              num.trees = ntreeOptimal,
                              tuneGrid = tGrid)
impPlotsOptimalRanger4 <- plot(varImp(optimalRanger4),top = 15)
save(list = c("optimalRanger4","impPlotsOptimalRanger4"),file = "Data/OtherData/optimalRangerResults4.RData")
print(paste("Model finished and saved at",Sys.time()))
runtime$optimalRanger4 <- Sys.time() - runtime$optimalRanger4

runtime$optimalRanger5 <- Sys.time()
sparseOptimal <- 4
optimalRanger5 <- caret::train(x = tSparseList[[sparseOptimal]][,-1],
                              y = tSparseList[[sparseOptimal]][,1][[1]],
                              method = "ranger",
                              importance = "impurity",
                              num.trees = ntreeOptimal,
                              tuneGrid = tGrid)
impPlotsOptimalRanger5 <- plot(varImp(optimalRanger5),top = 15)
save(list = c("optimalRanger5","impPlotsOptimalRanger5"),file = "Data/OtherData/optimalRangerResults5.RData")
print(paste("Model finished and saved at",Sys.time()))
runtime$optimalRanger5 <- Sys.time() - runtime$optimalRanger5

runtime$optimalRanger6 <- Sys.time()
sparseOptimal <- 3
optimalRanger6 <- caret::train(x = tSparseList[[sparseOptimal]][,-1],
                              y = tSparseList[[sparseOptimal]][,1][[1]],
                              method = "ranger",
                              importance = "impurity",
                              num.trees = ntreeOptimal,
                              tuneGrid = tGrid)
impPlotsOptimalRanger6 <- plot(varImp(optimalRanger6),top = 15)
save(list = c("optimalRanger6","impPlotsOptimalRanger6"),file = "Data/OtherData/optimalRangerResults6.RData")
print(paste("Model finished and saved at",Sys.time()))
runtime$optimalRanger6 <- Sys.time() - runtime$optimalRanger6

```

### Training Candidate Final Models - Mtry of 488
```{r}
mtryOptimal <- 488
ntreeOptimal <- 500
tGrid <- expand.grid(
                     .mtry = mtryOptimal,
                     .splitrule = "variance",
                     .min.node.size = 5)

sparseOptimal <-2
runtime$sparsityFiveOptimalRanger2 <- Sys.time()
sparsityFiveOptimalRanger2 <- caret::train(x = tSparseList[[sparseOptimal]][,-1],
                              y = tSparseList[[sparseOptimal]][,1][[1]],
                              method = "ranger",
                              importance = "impurity",
                              num.trees = ntreeOptimal,
                              tuneGrid = tGrid)
impPlotsSparsityFiveOptimalRanger2 <- plot(varImp(sparsityFiveOptimalRanger2),top = 15)
save(list = c("sparsityFiveOptimalRanger2","impPlotsSparsityFiveOptimalRanger2"),file = "Data/OtherData/sparsityFiveOptimalRanger2.RData")
print(paste("Model finished and saved at",Sys.time()))
runtime$sparsityFiveOptimalRanger2 <- Sys.time() - runtime$sparsityFiveOptimalRanger2

sparseOptimal <-3
runtime$sparsityFiveOptimalRanger3 <- Sys.time()
sparsityFiveOptimalRanger3 <- caret::train(x = tSparseList[[sparseOptimal]][,-1],
                              y = tSparseList[[sparseOptimal]][,1][[1]],
                              method = "ranger",
                              importance = "impurity",
                              num.trees = ntreeOptimal,
                              tuneGrid = tGrid)
impPlotsSparsityFiveOptimalRanger3 <- plot(varImp(sparsityFiveOptimalRanger3),top = 15)
save(list = c("sparsityFiveOptimalRanger3","impPlotsSparsityFiveOptimalRanger3"),file = "Data/OtherData/sparsityFiveOptimalRanger3.RData")
print(paste("Model finished and saved at",Sys.time()))
runtime$sparsityFiveOptimalRanger3 <- Sys.time() - runtime$sparsityFiveOptimalRanger3

sparseOptimal <-4
runtime$sparsityFiveOptimalRanger2 <- Sys.time()
sparsityFiveOptimalRanger4 <- caret::train(x = tSparseList[[sparseOptimal]][,-1],
                              y = tSparseList[[sparseOptimal]][,1][[1]],
                              method = "ranger",
                              importance = "impurity",
                              num.trees = ntreeOptimal,
                              tuneGrid = tGrid)
impPlotsSparsityFiveOptimalRanger4 <- plot(varImp(sparsityFiveOptimalRanger4),top = 15)
save(list = c("sparsityFiveOptimalRanger4","impPlotsSparsityFiveOptimalRanger4"),file = "Data/OtherData/sparsityFiveOptimalRanger4.RData")
print(paste("Model finished and saved at",Sys.time()))
runtime$sparsityFiveOptimalRanger4 <- Sys.time() - runtime$sparsityFiveOptimalRanger4

sparseOptimal <-5
runtime$sparsityFiveOptimalRanger5 <- Sys.time()
sparsityFiveOptimalRanger5 <- caret::train(x = tSparseList[[sparseOptimal]][,-1],
                              y = tSparseList[[sparseOptimal]][,1][[1]],
                              method = "ranger",
                              importance = "impurity",
                              num.trees = ntreeOptimal,
                              tuneGrid = tGrid)
impPlotsSparsityFiveOptimalRanger5 <- plot(varImp(sparsityFiveOptimalRanger5),top = 15)
save(list = c("sparsityFiveOptimalRanger5","impPlotsSparsityFiveOptimalRanger5"),file = "Data/OtherData/sparsityFiveOptimalRanger5.RData")
print(paste("Model finished and saved at",Sys.time()))
runtime$sparsityFiveOptimalRanger5 <- Sys.time() - runtime$sparsityFiveOptimalRanger5

sparseOptimal <-6
runtime$sparsityFiveOptimalRanger6 <- Sys.time()
sparsityFiveOptimalRanger6 <- caret::train(x = tSparseList[[sparseOptimal]][,-1],
                              y = tSparseList[[sparseOptimal]][,1][[1]],
                              method = "ranger",
                              importance = "impurity",
                              num.trees = ntreeOptimal,
                              tuneGrid = tGrid)
impPlotsSparsityFiveOptimalRanger6 <- plot(varImp(sparsityFiveOptimalRanger6),top = 15)
save(list = c("sparsityFiveOptimalRanger6","impPlotsSparsityFiveOptimalRanger6"),file = "Data/OtherData/sparsityFiveOptimalRanger6.RData")
print(paste("Model finished and saved at",Sys.time()))
runtime$sparsityFiveOptimalRanger6 <- Sys.time() - runtime$sparsityFiveOptimalRanger6

sparseOptimal <-7
runtime$sparsityFiveOptimalRanger7 <- Sys.time()
sparsityFiveOptimalRanger7 <- caret::train(x = tSparseList[[sparseOptimal]][,-1],
                              y = tSparseList[[sparseOptimal]][,1][[1]],
                              method = "ranger",
                              importance = "impurity",
                              num.trees = ntreeOptimal,
                              tuneGrid = tGrid)
impPlotsSparsityFiveOptimalRanger7 <- plot(varImp(sparsityFiveOptimalRanger7),top = 15)
save(list = c("sparsityFiveOptimalRanger7","impPlotsSparsityFiveOptimalRanger7"),file = "Data/OtherData/sparsityFiveOptimalRanger7.RData")
print(paste("Model finished and saved at",Sys.time()))
runtime$sparsityFiveOptimalRanger7 <- Sys.time() - runtime$sparsityFiveOptimalRanger7

sparseOptimal <-8
runtime$sparsityFiveOptimalRanger8 <- Sys.time()
sparsityFiveOptimalRanger8 <- caret::train(x = tSparseList[[sparseOptimal]][,-1],
                              y = tSparseList[[sparseOptimal]][,1][[1]],
                              method = "ranger",
                              importance = "impurity",
                              num.trees = ntreeOptimal,
                              tuneGrid = tGrid)
impPlotsSparsityFiveOptimalRanger8 <- plot(varImp(sparsityFiveOptimalRanger8),top = 15)
save(list = c("sparsityFiveOptimalRanger8","impPlotsSparsityFiveOptimalRanger8"),file = "Data/OtherData/sparsityFiveOptimalRanger8.RData")
print(paste("Model finished and saved at",Sys.time()))
runtime$sparsityFiveOptimalRanger8 <- Sys.time() - runtime$sparsityFiveOptimalRanger8
```

## Candidate Models - Results
### Combining Results of Candidate Final Models - Mtry of 913
```{r}
results <- c(list.files("Data/OtherData/","optimalRangerResults*"))
lapply(X = paste("Data/OtherData/",results,sep=""),FUN = load,envir=.GlobalEnv,)  #loads models

optimalRangerResults <- data.frame(matrix(ncol = 8,nrow = 1))
colnames(optimalRangerResults) <- c("modelType","trainDataSize","sparsity","rsquared","MSE","NumTrees","mTry","minNodeSize")
optimalRangerResults[1,] <- 1

#I had only orignally planned to do this for 3 rows so the non listed implementation is not ideal. Sorry.
row1  <- c("Bag of Words",optimalRanger$finalModel$num.samples,
           eightLevelSparsity[6],
           optimalRanger$finalModel$r.squared,
           optimalRanger$finalModel$prediction.error,
           optimalRanger$finalModel$num.trees,
           optimalRanger$finalModel$mtry,
           optimalRanger$finalModel$min.node.size)
row2 <- c("Bag of Words",optimalRanger2$finalModel$num.samples,
           eightLevelSparsity[7],
           optimalRanger2$finalModel$r.squared,
           optimalRanger2$finalModel$prediction.error,
           optimalRanger2$finalModel$num.trees,
           optimalRanger2$finalModel$mtry,
           optimalRanger2$finalModel$min.node.size)
row3 <- c("Bag of Words",optimalRanger3$finalModel$num.samples,
           eightLevelSparsity[8],
           optimalRanger3$finalModel$r.squared,
           optimalRanger3$finalModel$prediction.error,
           optimalRanger3$finalModel$num.trees,
           optimalRanger3$finalModel$mtry,
           optimalRanger3$finalModel$min.node.size)  
row4 <- c("Bag of Words",optimalRanger4$finalModel$num.samples,
           eightLevelSparsity[5],
           optimalRanger4$finalModel$r.squared,
           optimalRanger4$finalModel$prediction.error,
           optimalRanger4$finalModel$num.trees,
           optimalRanger4$finalModel$mtry,
           optimalRanger4$finalModel$min.node.size)
row5 <- c("Bag of Words",optimalRanger5$finalModel$num.samples,
           eightLevelSparsity[4],
           optimalRanger5$finalModel$r.squared,
           optimalRanger5$finalModel$prediction.error,
           optimalRanger5$finalModel$num.trees,
           optimalRanger5$finalModel$mtry,
           optimalRanger5$finalModel$min.node.size)  
row6 <- c("Bag of Words",optimalRanger6$finalModel$num.samples,
           eightLevelSparsity[3],
           optimalRanger6$finalModel$r.squared,
           optimalRanger6$finalModel$prediction.error,
           optimalRanger6$finalModel$num.trees,
           optimalRanger6$finalModel$mtry,
           optimalRanger6$finalModel$min.node.size)  
row7 <- c("Bag of Words",optimalRanger7$finalModel$num.samples,
           eightLevelSparsity[2],
           optimalRanger7$finalModel$r.squared,
           optimalRanger7$finalModel$prediction.error,
           optimalRanger7$finalModel$num.trees,
           optimalRanger7$finalModel$mtry,
           optimalRanger7$finalModel$min.node.size)  

optimalRangerResults <- rbind(optimalRangerResults,row1,row2,row3, row4,row5, row6, row7)
optimalRangerResults <- optimalRangerResults[2:nrow(optimalRangerResults),]
optimalRangerResults$modelName <- paste(optimalRangerResults$modelType,optimalRangerResults$NumTrees,sep="; nTrees: ")
```


### Comparing Candidate Final Models - Mtry of 913
```{r}
scalingCoef <- .065
colors <- c("R Squared" = "red", "MSE" = "blue")

ggplot(data = optimalRangerResults, aes(x=sparsity, group=1)) +
  geom_line( aes(y=as.double(MSE)/scalingCoef, color = "MSE")) + 
  geom_line( aes(y=as.double(rsquared), color = "R Squared")) +
  scale_color_manual(values = colors) +
  labs(x = "Text Sparsity",color = "Legend")+ theme(legend.position = "bottom") +
  scale_y_continuous(
    name = "R Squared",     # Features of the first axis
    sec.axis = sec_axis(~.*scalingCoef, name="Mean Squared Error"))  # Add a second axis and specify its features

impPlotsOptimalRanger
impPlotsOptimalRanger2
impPlotsOptimalRanger3
impPlotsOptimalRanger4
impPlotsOptimalRanger5
impPlotsOptimalRanger6
impPlotsOptimalRanger7
```


### Combining Results of Candidate Final Models - Mtry of 488
```{r}
results <- c(list.files("Data/OtherData/","sparsityFive*"))
lapply(X = paste("Data/OtherData/",results,sep=""),FUN = load,envir=.GlobalEnv,)  #loads models
eightLevelSparsity <- c(.4,.5,.6,.7,.8,.9,.95,.99)

sparsityFiveOptimalRangerResults <- data.frame(matrix(ncol = 8,nrow = 1))
colnames(sparsityFiveOptimalRangerResults) <- c("modelType","trainDataSize","sparsity","rsquared","MSE","NumTrees","mTry","minNodeSize")
sparsityFiveOptimalRangerResults[1,] <- 1

#I had only orignally planned to do this for 3 rows so the non listed implementation is not ideal. Sorry.

row2 <- c("Bag of Words",sparsityFiveOptimalRanger2$finalModel$num.samples,
           eightLevelSparsity[2],
           sparsityFiveOptimalRanger2$finalModel$r.squared,
           sparsityFiveOptimalRanger2$finalModel$prediction.error,
           sparsityFiveOptimalRanger2$finalModel$num.trees,
           sparsityFiveOptimalRanger2$finalModel$mtry,
           sparsityFiveOptimalRanger2$finalModel$min.node.size)
row3 <- c("Bag of Words",sparsityFiveOptimalRanger3$finalModel$num.samples,
           eightLevelSparsity[3],
           sparsityFiveOptimalRanger3$finalModel$r.squared,
           sparsityFiveOptimalRanger3$finalModel$prediction.error,
           sparsityFiveOptimalRanger3$finalModel$num.trees,
           sparsityFiveOptimalRanger3$finalModel$mtry,
           sparsityFiveOptimalRanger3$finalModel$min.node.size)  
row4 <- c("Bag of Words",sparsityFiveOptimalRanger4$finalModel$num.samples,
           eightLevelSparsity[4],
           sparsityFiveOptimalRanger4$finalModel$r.squared,
           sparsityFiveOptimalRanger4$finalModel$prediction.error,
           sparsityFiveOptimalRanger4$finalModel$num.trees,
           sparsityFiveOptimalRanger4$finalModel$mtry,
           sparsityFiveOptimalRanger4$finalModel$min.node.size)
row5 <- c("Bag of Words",sparsityFiveOptimalRanger5$finalModel$num.samples,
           eightLevelSparsity[5],
           sparsityFiveOptimalRanger5$finalModel$r.squared,
           sparsityFiveOptimalRanger5$finalModel$prediction.error,
           sparsityFiveOptimalRanger5$finalModel$num.trees,
           sparsityFiveOptimalRanger5$finalModel$mtry,
           sparsityFiveOptimalRanger5$finalModel$min.node.size)  
row6 <- c("Bag of Words",sparsityFiveOptimalRanger6$finalModel$num.samples,
           eightLevelSparsity[6],
           sparsityFiveOptimalRanger6$finalModel$r.squared,
           sparsityFiveOptimalRanger6$finalModel$prediction.error,
           sparsityFiveOptimalRanger6$finalModel$num.trees,
           sparsityFiveOptimalRanger6$finalModel$mtry,
           sparsityFiveOptimalRanger6$finalModel$min.node.size)  
row7 <- c("Bag of Words",sparsityFiveOptimalRanger7$finalModel$num.samples,
           eightLevelSparsity[7],
           sparsityFiveOptimalRanger7$finalModel$r.squared,
           sparsityFiveOptimalRanger7$finalModel$prediction.error,
           sparsityFiveOptimalRanger7$finalModel$num.trees,
           sparsityFiveOptimalRanger7$finalModel$mtry,
           sparsityFiveOptimalRanger7$finalModel$min.node.size)  
row8 <- c("Bag of Words",sparsityFiveOptimalRanger8$finalModel$num.samples,
           eightLevelSparsity[8],
           sparsityFiveOptimalRanger8$finalModel$r.squared,
           sparsityFiveOptimalRanger8$finalModel$prediction.error,
           sparsityFiveOptimalRanger8$finalModel$num.trees,
           sparsityFiveOptimalRanger8$finalModel$mtry,
           sparsityFiveOptimalRanger8$finalModel$min.node.size) 

sparsityFiveOptimalRangerResults <- rbind(sparsityFiveOptimalRangerResults,row2,row3, row4,row5, row6, row7, row8)
sparsityFiveOptimalRangerResults <- sparsityFiveOptimalRangerResults[2:nrow(sparsityFiveOptimalRangerResults),]
sparsityFiveOptimalRangerResults$modelName <- paste(sparsityFiveOptimalRangerResults$modelType,sparsityFiveOptimalRangerResults$NumTrees,sep="; nTrees: ")
```

### Comparing Candidate Final Models - Mtry of 488
```{r}
scalingCoef <- .067
colors <- c("R Squared" = "red", "MSE" = "blue")

ggplot(data = sparsityFiveOptimalRangerResults, aes(x=sparsity, group=1)) +
  geom_line( aes(y=as.double(MSE)/scalingCoef, color = "MSE")) + 
  geom_line( aes(y=as.double(rsquared), color = "R Squared")) +
  scale_color_manual(values = colors) +
  labs(x = "Text Sparsity",color = "Legend")+ theme(legend.position = "bottom") +
  scale_y_continuous(
    name = "R Squared",     # Features of the first axis
    sec.axis = sec_axis(~.*scalingCoef, name="Mean Squared Error"))  # Add a second axis and specify its features

impPlotsSparsityFiveOptimalRanger2
impPlotsSparsityFiveOptimalRanger3
impPlotsSparsityFiveOptimalRanger4
impPlotsSparsityFiveOptimalRanger5
impPlotsSparsityFiveOptimalRanger6
impPlotsSparsityFiveOptimalRanger7
```


# Final Model Specification
```{r}
finalRanger <- sparsityFiveOptimalRanger5
save(finalRanger,file = "Full_Trained_Model.RData")
finalRangerImpPlot <- plot(varImp(finalRanger),top = 15)

comparisonResults <- c("Model_Type", "Mean Squared Error", "R Squared")
comparisonResults <- rbind(comparisonResults,c("Full Model",finalRanger$finalModel$prediction.error,finalRanger$finalModel$r.squared))

```

# Model Comparisons
## Structured Features Model
```{r}
runtime$structured <- Sys.time()

sparseOptimal <- 5
mtryOptimal <- 488
ntreeOptimal <- 500
structuredData <- tSparseList[[1]][,c(1:9)]

tGrid <- expand.grid(
                     .mtry = min(mtryOptimal,ncol(structuredData)-1),
                     .splitrule = "variance",
                     .min.node.size = 5)


rangerStructured <- caret::train(
                                      x = structuredData[,-1],
                                      y = structuredData[,1][,1][[1]],
                                      method = "ranger",
                                      importance = "impurity",
                                      tuneGrid = tGrid,
                                      num.trees = ntreeOptimal)

structuredImpPlot <- plot(varImp(rangerStructured),top = 8, height = 2, width = 5)
structuredImpPlot

comparisonResults <- rbind(comparisonResults,c("Structured Features",rangerStructured$finalModel$prediction.error, rangerStructured$finalModel$r.squared))
save(list = c("rangerStructured","structuredImpPlot"),file = "Data/OtherData/rangerResultsStructured.RData")
print(paste("Model",ii,"finished and saved at",Sys.time()))

runtime$structured <- Sys.time() - runtime$structured
```

## Baseline Model
```{r}
runtime$baseline <- Sys.time()

sparseOptimal <- 5
mtryOptimal <- 488
ntreeOptimal <- 500
baselineData <- tSparseList[[1]][,c(1:3)]

tGrid <- expand.grid(
                     .mtry = min(mtryOptimal,ncol(baselineData)-1),
                     .splitrule = "variance",
                     .min.node.size = 5)


rangerBaseline <- caret::train(
                                      x = baselineData[,-1],
                                      y = baselineData[,1][,1][[1]],
                                      method = "ranger",
                                      importance = "impurity",
                                      tuneGrid = tGrid,
                                      num.trees = ntreeOptimal)

baselineImpPlot <- plot(varImp(rangerBaseline),top = 2)
baselineImpPlot
comparisonResults <- rbind(comparisonResults,c("Baseline Features",rangerBaseline$finalModel$prediction.error, rangerBaseline$finalModel$r.squared))

save(list = c("rangerBaseline","baselineImpPlot"),file = "Data/OtherData/rangerResultsBaseline.RData")
print(paste("Model",ii,"finished and saved at",Sys.time()))

runtime$baseline <- Sys.time() - runtime$baseline
```



## Graphing Final Model Comparisons
```{r}
comparisonResults <- as.data.frame(comparisonResults)
names(comparisonResults) <- comparisonResults[1,]
comparisonResults <- comparisonResults[-1,]
comparisonResultsTall <- gather(comparisonResults, key = Measure, value = Values, -Model_Type)
comparisonResultsTall$Model_Type <- factor(comparisonResultsTall$Model_Type, levels = c("Full Model","Structured Features","Baseline Features"))
data
comparisonResultsTall

ggplot(comparisonResultsTall, aes(fill = Measure,y = as.double(Values), x = Model_Type)) + geom_bar(position = "dodge", stat = "identity") + labs(x = "Model Type", y = "Values", fill = "Legend") + theme(legend.position = "bottom")

comparisonResults$Model_Type <- factor(comparisonResults$Model_Type, levels = c("Full Model","Structured Features","Baseline Features"))

ggplot(comparisonResults, aes(x = Model_Type, fill = Model_Type)) + geom_col(aes(y = as.double(`Mean Squared Error`))) + labs(x = "Model Type", y = "Mean Squared Error", fill= "Legend") + theme(legend.position = "bottom") 

ggplot(comparisonResults, aes(x = Model_Type, fill = Model_Type)) + geom_col(aes(y = as.double(`R Squared`))) + labs(x = "Model Type", y = "R Squared", fill= "Legend") + theme(legend.position = "bottom")
```


# Predictions
## Data Processing
### Pulling Review Data for 2020-2021
```{r}
load("Data/OtherData/Compiled_Thesis_Data.RData")
predictorReviewData <- review_data %>% filter(!is.na(id)) #removes rows with NA listing IDs. 
predictorReviewData$date <- as.Date(predictorReviewData$date)
predictorReviewData <- predictorReviewData %>% filter(date >= as.Date("2019-12-31"))  #only keep reviews after 2019

predictorReviewData <- predictorReviewData %>% subset(select = c(listing_id,comments)) #keep only listing_id and text data
predictorReviewData <- predictorReviewData %>% group_by(listing_id) %>% mutate(numReviews = n()) #creates a feature for the number of reviews per listing
predictorReviewData <- aggregate(comments ~ listing_id + numReviews, predictorReviewData, paste, collapse = " ") #combines all text data for a given listing into one row for that listing
runtime$loadAndFilter <- Sys.time() - runtime$loadAndFilter
```


### Merging Airbnb (Listing Level) and Census Data (Tract Level)
```{r}
predictorListingData <- listing_data %>% subset(select = c("id","bedrooms","price","minimum_nights","review_scores_rating",
                                                             "review_scores_location","tractFIPS2010"))

colnames(predictorListingData)[which(names(predictorListingData) == "price")] <- "listing_price" #renames column titled price to "listing_price". 
                                                                                 #Prevents error of repeated column name in tSparse

predictorAirbnbData <- inner_join(predictorListingData,predictorReviewData,by = c("id"="listing_id"))

tCensusData <- gentrifiableCensusDataWithDistributionsWide %>% subset(select = c("tractFIPS","NAME.2014","totalPop.2014","popGrowth","gentrificationChange"))
predictorTractData  <- inner_join(tCensusData,predictorAirbnbData,by = c("tractFIPS"="tractFIPS2010"))
```

### Aggregating Airbnb Data to Tract Level
```{r}
predictorTractReviews <- predictorTractData %>% subset(select = c(tractFIPS,comments))
predictorTractReviews <- aggregate(comments ~ tractFIPS, predictorTractReviews, paste,collapse = " ")

predictorTractDataNoText <-  predictorTractData %>% subset(select = -c(comments))

predictorTractDataNoText <- predictorTractDataNoText %>% group_by(tractFIPS) %>%
                                summarise(gentrificationChange = mean(gentrificationChange,na.rm = TRUE),
                                            totalPop.2014 = mean(totalPop.2014,na.rm = TRUE),
                                            popGrowth = mean(popGrowth,na.rm = TRUE),
                                            review_scores_rating = mean(review_scores_rating,na.rm = TRUE),
                                            review_scores_location = mean(review_scores_location,na.rm = TRUE),
                                            bedrooms = mean(bedrooms,na.rm = TRUE),
                                            listing_price = mean(parse_number(listing_price),na.rm = TRUE),
                                            numListings = n(),
                                            numReviews = sum(numReviews))


predictorTractData <- inner_join(predictorTractDataNoText,predictorTractReviews, by = "tractFIPS")
runtime$finalCompilation <- Sys.time() - runtime$finalCompilation
```


### Cleaning Text Data
Removes formatting, stopwords, and stems text. Takes a significant amount of time to run.
```{r}
runtime$corpus <- Sys.time()
corpus <- Corpus(VectorSource(tractData$comments)) 
corpus <- tm_map(corpus, PlainTextDocument)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeWords, "New") #removing for place names (e.g. New York, New Jersey)
corpus <- tm_map(corpus, tolower)
corpus <- tm_map(corpus, removeWords, c("airbnb",stopwords("english"),stopwords("spanish"),locationWords))  #remove stopwords
corpus <- tm_map(corpus, stemDocument)
#save(corpus,file = "Data/OtherData/processed2020_2021Corpus.RData")  #commented out so as to not accidentally overwrite saved data
runtime$corpus <- Sys.time() - runtime$corpus
```

### Creating Prediction Text Data
```{r}
loadRData <- function(fileName){
#loads an RData file, and returns it
    load(fileName)
    get(ls()[ls() != "fileName"])
}

predictorCorpus <- loadRData("Data/OtherData/processed2020_2021Corpus.RData")
load("Data/OtherData/processedFullCorpus.RData") #loads 2015-2019 corpus
sparseOptimal <- 0.8
sparsePredictor <- 0.999

library(tm)
freq.dtm <- DocumentTermMatrix(corpus, control = list(wordLengths = c(3,10))) 
pred.dtm <- DocumentTermMatrix(predictorCorpus) 
freq.dtm <- removeSparseTerms(freq.dtm, sparseOptimal)
pred.dtm <- removeSparseTerms(pred.dtm, sparsePredictor)
freq.dtm.mat <- as.matrix(freq.dtm) # training
pred.dtm.mat <- as.matrix(pred.dtm) # testing

##ADDING IN THIS LINE TO REPLACE THE TRAINING CORPUS WITH WHAT WAS ACUTALLY USED
freq.dtm.mat <- as.matrix(finalRanger$trainingData)
##ENDING THE ADDED SECTION

xxdtm <- data.frame(pred.dtm.mat[,intersect(colnames(pred.dtm.mat),
                                           colnames(freq.dtm.mat))])
yydtm <- read.table(textConnection(""), col.names = colnames(freq.dtm.mat),
                 colClasses = "integer")
detach("package:tidyverse", unload=TRUE)  #removes dplyr package to avoid conflicts with plyr
library(plyr)
library(tidyverse)
zzdtm <- rbind.fill(xxdtm, yydtm)
predictorDataRaw  <- cbind(predictorTractDataNoText,zzdtm)
```

## Final Predictions
```{r}
predictorData <- predictorDataRaw[!is.na(predictorData$bedrooms),]
predictorData <- predictorData[!is.na(predictorData$gentrificationChange),]
namesInFinalRanger_NotpredictorData <- setdiff(names(finalRanger$trainingData),names(predictorData))
namesInpredictorData_NotFinalRanger <- setdiff(names(predictorData),names(finalRanger$trainingData))
incomplete <- as.data.frame(which(is.na(predictorData), arr.ind=TRUE))
incompleteCols <- incomplete %>% group_by(col) %>% summarize(n=n())
incompleteCols <- incompleteCols$col[incompleteCols$col>1000]
predictorData[,incompleteCols] <- 0  #sets word frequencies to 0 for words which weren't used at all
predictorData <- predictorData[complete.cases(predictorData),]
predictorDataFinal <- predictorData[,3:ncol(predictorData)]

####PREDICTION
finalRangerPredictions <- predict(finalRanger,newdata = predictorDataFinal)
####END PREDICTION

predictedGentrificationTracts <- cbind(finalRangerPredictions,predictorData) 
meanDif <- (predictedGentrificationTracts$finalRangerPredictions - predictedGentrificationTracts$gentrificationChange)
colnames(predictedGentrificationTracts)[which(names(predictedGentrificationTracts) == "gentrificationChange")] <- "gentrificationChange2014_2019"
save(predictedGentrificationTracts,file = "Data/OtherData/predictedGentrificationByTract.RData")
```

## Mapping Predicted Gentrification
```{r, warning=FALSE}
load("Data/OtherData/predictedGentrificationByTract.RData")
ii=1
library(acs)
tractGeom <- data.frame()
load("Data/OtherData/Compiled_Thesis_Data.RData")
load("Data/OtherData/msaMappingData.RData")
includedStates <- listing_data %>% group_by(nchar(stateAndCountyFIPS2010)) %>% summarize() %>% drop_na()
includedStates <- listing_data %>% group_by(listing_data$state) %>% summarize() %>% drop_na()
names(includedStates)<-"state_FIPS"

for (fipsCode in includedStates$state_FIPS) {
    stateTractGeom <- tracts(state = fipsCode)
    tractGeom <- rbind(tractGeom,stateTractGeom)
}
tractGeom1 <- tractGeom %>% subset(select=c("GEOID","geometry"))
gentrificationByTract <- predictedGentrificationTracts[,1:3]
gentrificationByTractGeoms <- geo_join(data_frame = gentrificationByTract, spatial_data = msaMappingData, by_df = "tractFIPS",by_sp = "GEOID")


#gentrificationByTractGeoms <- geo_join(data_frame = gentrificationByTract,spatial_data = tractGeom1,by_df = "tractFIPS",by_sp = "GEOID")


#mappableGentrificationPrediction <- geo_join(gentrificationByTractGeoms,msaMappingData, by = "GEOID")

predictedGentMaps <- ""
for (MSA in uniqueMSAs$CBSA.Code) {

  cityCensusData <- filter(gentrificationByTractGeoms,gentrificationByTractGeoms$CBSA.Code.x.2014==MSA)
  predictedGentMaps[ii] <- plot(cityCensusData["finalRangerPredictions"],
                                sub = "Predicted Gentrification Change Jan 2020 - Oct 2021",
                                main=paste(cityCensusData$CBSA.Title.x.2014[1]))
  ii<-ii+1
}
runtime$mapping <- Sys.time() - runtime$mapping
save(predictedGentMaps)

```
